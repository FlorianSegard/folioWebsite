<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-designer, initial-scale=1.0">
    <title>My Website</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header style="position: sticky; top: 0; z-index: 1000;">
        <nav>
            <ul>
                <li><a href="#project">Projects</a></li>
                <li><a href="#about">About me</a></li>
                <li><a href="#contact">Contact</a></li>
            </ul>
        </nav>
    </header>
    <section id="project">
        <h1>Projects</h1>
        <div id="project-list">
            <div class="project-item">
                <h3>Data Engineering</h3>
                <p>
                    This project involved building a robust and resilient architecture using <strongDescr>Kafka streams</strongDescr>, a <strongDescr>data lake</strongDescr>, and <strongDescr>Spark</strongDescr> to ensure scalability.<br>
                    We utilized <strongDescr>Scala</strongDescr> as our programming language, emphasizing functional programming to ensure the purity of functions and achieve optimal <strongDescr>scalability</strongDescr> with Spark.<br>
                    The architecture was designed to handle the transmission of large volumes of small datas effectively.</p>
                <ul>
                    <li><img src="images/dataeng/kafka_logo.png" alt="Kafka Streams Logo" class="logo-image"> Kafka Streams</li>
                    <li><img src="images/dataeng/spark_logo.png" alt="Apache Spark Logo" class="logo-image"> Apache Spark</li>
                    <li><img src="images/dataeng/minio_logo.png" alt="Minio Logo" class="logo-image"> Minio Data Lake</li>
                    <li><img src="images/dataeng/scala_logo.png" alt="Scala Logo" class="logo-image"> Scala</li>
                </ul>
                <button class="view-btn">See More</button>
                <div class="project-description" style="display: none;">
                    <h3>I - Description</h3>
                    <p>
                        <strong>Situation:</strong> 
                        Come up with a startup idea of an innovative service based on:
                        <ul class="bullet-list">
                            <li>IOT devices</li>
                            <li>An information system</li>
                        </ul>
                    </p>
                    <p>
                        <strong>IOT Devices:</strong> 
                        These devices must emit data every few minutes (or seconds). Assuming the startup is successful, 
                        there will be millions of these devices. We consider that you've managed to make a working prototype. 
                        Every data emitted by the devices must contain:
                        <ul>
                            <li>Timestamps</li>
                            <li>Device ID</li>
                            <li>Latitude and Longitude</li>
                            <li>Any other field you find useful (e.g., temperature, humidity, etc.)</li>
                        </ul>
                    </p>
                    <p>
                        <strong>Your Information System Must Provide:</strong>
                        <ul>
                            <li>An urgent service referred to as "alert"</li>
                            <li>A long-term analytics service</li>
                        </ul>
                    </p>
                    <p>
                        <strong>Recommended System Architecture:</strong> 
                        Based on the preliminary questions, your solution is very likely to include:
                        <ul>
                            <li>At least one distributed storage</li>
                            <li>At least one distributed stream processing framework</li>
                            <li>At least two stream consumers</li>
                        </ul>
                    </p>
                    <h3>II - Our solution</h3>
                    <p>
                        Our idea was to assess the danger posed by individuals and alert the police when necessary. We use a "dangerousity" index, a float ranging from 0 to 1. For testing the architecture, we simply generated a random number within this range.
                    </p>
                    <p>
                        We implemented a <strongDescr>Kafka stream</strongDescr> with two <strongDescr>brokers</strongDescr>, each configured with 3 <strongDescr>partitions</strongDescr> and <strongDescr>replicates</strongDescr> across all <strongDescr>topics</strongDescr>. This setup ensured that even if a broker failed, the project would continue functioning without any data loss, demonstrating our project's scalability.
                    </p>
                    <p>
                        There were three sources of data, each representing drones, transmitting data every 0.1 seconds. All data were sent to a Kafka stream under the topic "drone-data."
                    </p>
                    <p>
                        A <strongDescr>consumer</strongDescr> named "Consumer Datalake" stores the data on the <strongDescr>Minio</strongDescr> datalake. Another consumer, "Consumer Alert," monitors the "dangerousity" index. If it exceeds 0.9, it forwards the data to the topic "high-danger-alerts."
                    </p>
                    <p>
                        Additionally, "Consumer AlertProcess" is tasked with triggering alerts via the Discord API to a Discord server when high danger alerts are received.
                    </p>
                    <p>
                        <strong>Below is the architectural diagram that summarizes our setup:</strong>
                    </p>
                    <p>
                        <img src="images/dataeng/architectureDataEng.png" alt="Architecture Diagram" class="full-width-image">
                    </p>
                </div>
            </div>

            <div class="project-item">
                <h3>CNN Competitons</h3>
                <p>
                    We participated in two competitions: one involved creating a custom <strongDescr>Convolutional Neural Network</strongDescr> (CNN) using <strongDescr>TensorFlow</strongDescr> and <strongDescr>Keras</strongDescr>, and the other involved fine-tuning a model with PyTorch.<br>
                    Both competitions focused on classifying boat images sized 128x192 pixels into 10 different categories.
                </p>
                <ul>
                    <li><img src="images/CNN/tensorflow_logo.webp" alt="Tensorflow Logo" class="logo-image"> Tensorflow</li>
                    <li><img src="images/CNN/pytorch_logo.webp" alt="Pytorch Logo" class="logo-image"> Pytorch</li>
                </ul>
                <button class="view-btn">See More</button>
                <div class="project-description" style="display: none;">
                    <h3>I - Description</h3>
                    <p>
                        <strong>Competition 1</strong>
                    </p>
                    <p>
                        <ul>
                            <li>Write a CNN by hand with fewer than 30 layers (include print("Number of layers: ", len(model.layers)) in your sheet; I will grep it).</li>
                            <li>Submit your results.</li>
                            <li>Check your ranking (and possibly start over).</li>
                        </ul>
                    </p>
                    <p>
                        <strong>Competition 2</strong>
                    </p>
                    <p>
                        <ul>
                            <li>This involves starting with an existing network and adapting it for this project. You are allowed to do anything, but it must be able to run on Kaggle.</li>
                            <li>Submit your results.</li>
                            <li>Check your ranking (and possibly start over).</li>
                        </ul>
                    </p>

                    <h3>II - Hand made competiton</h3>
                    <p>
                        I tried copying different existing architecture like AlexNet or VGGNet, I also tried to build my own but it was not very concluent all this was done with keras <strongDescr>Tensorflow</strongDescr>.
                    </p>
                    <p>
                        In the end I took the VGGNet and did some testing around it which alowed me to have a testing accuracy of <strongDescr>0.91141</strongDescr> on images we didn't had access to.
                        Alowing me to be in the <strongDescr>4th place</strongDescr> of the competition.
                    </p>
                    <h3>III - Fine Tuning competition</h3>
                    <p>
                        We tried fine tuning different models and the one that worked the best for this exercise was a version of pre trained densenet121 from <strongDescr>Pyrtorch</strongDescr>.
                    </p>
                    <p>
                        And with testing we went up to <strongDescr>0.94891</strongDescr> on the images we didn't had access to.
                        Alowing me to be in the <strongDescr>1st place</strongDescr> of the competition.

                    </p>
                </div>
            </div>

            <div class="project-item">
                <h3>Big Data</h3>
                <p>
                    This project focused on processing a substantial amount of financial data in the most efficient manner possible, aiming for maximum speed without any loss of data.<br>
                    We developed a backend using <strongDescr>Pandas</strongDescr> to transfer data to the <strongDescr>PostgreSQL</strongDescr> database as effectively as possible.<br>
                    We then developped a <strongDescr>Dash</strongDescr> frontend to visualize the stored data.
                </p>
                <ul>
                    <!-- <li><img src="images/BigData/numpy_logo.png" alt="Numpy Logo" class="logo-image"> Numpy</li> -->
                    <li><img src="images/BigData/pandas_logo.png" alt="Pandas Logo" class="logo-image"> Pandas</li>
                    <li><img src="images/BigData/docker_logo.webp" alt="Docker Logo" class="logo-image"> Docker</li>
                    <li><img src="images/BigData/sql_logo.png" alt="SQL Logo" class="logo-image"> PostgreSQL</li>
                </ul>
                <button class="view-btn">See More</button>
                <div class="project-description" style="display: none;">
                    <h3>I - Description</h3>
                    <p>
                        <strong> 5 years of financial data</strong>
                    </p>
                    <p>
                        The work is done in two steps:
                        <ul>
                            <li>Read the data, clean it, and store it intelligently in a database.</li>
                            <li>Create a dashboard that allows for visualization of the data and performing some analyses.</li>
                        </ul>
                    </p>

                    <h3>II - Backend</h3>
                    <p>
                        The backend was the most substantial component of this project. It involved collecting, processing, and optimizing the data with <strongDescr>Pandas</strongDescr>, plus transferring it to the <strongDescr>PostgreSQL</strongDescr> database, which was challenging.
                    </p>
                    <p>
                        After optimizing the code, the total processing time for all the data was approximately <strongDescr>one hour</strongDescr> to read the datas from <strongDescr>271325 files</strongDescr>, clean them and stock the datas, even on less efficient computers.
                    </p>
                    <p>
                        One potential improvement to reduce processing time could be to implement multithreading. However, I encountered database issues and lacked sufficient time to address these.
                        Additionally, the project's high resource consumption with multithreading limited its compatibility across different computers.
                    </p>
                    <h3>III - Frontend</h3>
                    <p>
                        In our project, we've created a financial analytics dashboard using Dash in Python. The features we did were:
                    </p>
                    <p>
                        <ul>
                            <li>Display options for stock prices on a logarithmic scale, either as line charts or candlesticks.</li>
                            <li>Customizable date range selections for viewing stock data.</li>
                            <li>Multiple stock displays with individual color coding and an interactive legend for toggling visibility.</li>
                            <li>Bollinger Bands for analyzing stock volatility.</li>
                            <li>A data table showing daily stats like min, max, and average prices for selected stocks.</li>
                        </ul>
                    </p>
                </div>
            </div>

            <div class="project-item">
                <h3>Hackathon Albertschool AI vs AI</h3>
                <p>
                    The hackathon was held at the <strongDescr>Albertschool</strongDescr>, in collaboration with the <strongDescr>French Army</strongDescr>. <br>
                    Our task involved developing a <strongDescr>Natural Language Processing</strongDescr> (NLP) AI that could distinguish whether a message was written by a human or an AI. <br>
                    To process the data, we utilized <strongDescr>Pandas</strongDescr>, and for training our models, we employed <strongDescr>Scikit-Learn</strongDescr>.
                </p>
                <ul>
                    <li><img src="images/hackathon/pandas_logo.png" alt="Pandas Logo" class="logo-image"> Pandas</li>
                    <li><img src="images/hackathon/sklearn_logo.svg" alt="Sklearn Logo" class="logo-image"> Scikit-Learn</li>
                </ul>
                <button class="view-btn">See More</button>
                <div class="project-description" style="display: none;">
                    <h3>I - Description</h3>
                    <p>
                        <strong>"AI vs AI"</strong>: concerns the detection of texts emitted by a generative AI. This challenge takes place at <strongDescr>Albertschool</strongDescr> in Paris during three days.
                    </p>

                    <h3>II - Data cleaning and Pretreatment</h3>
                    <p>
                        During the data cleaning phase, we performed basic operations such as removing datas that were either NULL or not usable.
                    </p>
                    <p>
                        Subsequently, we applied various tokenization methods and assessed their performance across different models, utilizing libraries such as <strongDescr>NLTK</strongDescr>.
                    </p>
                    <p>
                        We also reviewed all sources of the texts and identified that the dataset was constructed using more than 30 different AIs.<br>
                        With this knowledge, we adjusted the number of texts sourced from each AI based on their initial accuracy in our existing model.
                    </p>
                    <h3>III - Models</h3>
                    <p>
                        We experimented with a variety of models for this project, compared their performances, and selected the best one. Here is the list of the different models we tested:
                    </p>
                    <p>
                        <table class="f1-table">
                            <tr>
                                <td><strongDescr>TF-IDF</strongDescr> with <strongDescr>GridSearch</strongDescr></td>
                                <td>F1-score: <strongDescr>0.9516</strongDescr></td>
                            </tr>
                            <tr>
                                <td><strongDescr>N-BAGS</strongDescr> with <strongDescr>GridSearch</strongDescr></td>
                                <td>F1-score: <strongDescr>0.9507</strongDescr></td>
                            </tr>
                            <tr>
                                <td><strongDescr>BiDirectionnal RNN</strongDescr></td>
                                <td>F1-score: <strongDescr>0.9437</strongDescr></td>
                            </tr>
                            <tr>
                                <td><strongDescr>Bert</strongDescr></td>
                                <td>F1-score: <strongDescr>0.8137</strongDescr></td>
                            </tr>
                        </table>
                
                    </p>
                </div>
            </div>

            <div class="project-item">
                <h3>NLP Project</h3>
                <p>
                    This <strongDescr>Epita</strongDescr> project served as a summary of all the key topics covered throughout the course.<br>
                    We were tasked with selecting or sourcing our own datasets our dataset was about <strongDescr>Music Genres</strongDescr>, and utilizing them to train various <strongDescr>NLP</strongDescr> <strongDescr>AI</strongDescr> and <strongDescr>Statistical</strongDescr> models.<br>
                    We used mainly used <strongDescr>Pandas</strongDescr> to clean the datas and <strongDescr>Scikit-Learn</strongDescr> to train our different models.
                </p>
                <ul>
                    <li><img src="images/nlpProject/pandas_logo.png" alt="Pandas Logo" class="logo-image"> Pandas</li>
                    <li><img src="images/nlpProject/sklearn_logo.svg" alt="Sklearn Logo" class="logo-image"> Scikit-Learn</li>
                </ul>
                <button class="view-btn">See More</button>
                <div class="project-description" style="display: none;">
                    <h3>I - Description</h3>

                    <p><strong>1- Data Processing:</strong></p>
                    <p>
                        <ul>
                            <li>Presentation: Describe the chosen dataset.</li>
                            <li>Pre-processing: Apply tokenization (regex and BPE), normalization (removal of stop words, lemmatization, converting to lowercase).</li>
                            <li>Statistics: Provide basic statistics (number of documents, tokens, frequency of tokens, etc.).</li>
                        </ul>
                    </p>
                    <p><strong>2- Models:</strong></p>
                    <p>
                        <ul>
                            <li>Training: Train various models (n-gram, naive Bayes, logistic regression, tf-idf, word2vec, neural networks).</li>
                            <li>Evaluation: Assess performance using standard metrics (perplexity, recall, precision, f1-score).</li>
                            <li>Optimization: Vary pre-processing and hyperparameters to improve performance.</li>
                            <li>Analysis: Discuss limitations and propose improvements.</li>
                        </ul>
                    </p>

                    <h3>II - Data cleaning and Pretreatment</h3>
                    <p>
                        We analyzed the dataset and then cleaned the data to ensure all entries were in English, eliminating any multilingual issues for training our models.
                    </p>
                    <p>
                        We implemented different <strongDescr>Tokenization</strongDescr> processes using <strongDescr>NLTK</strongDescr> and <strongDescr>Tiktoken</strongDescr>,
                        which segment the text into smaller units. We also applied several <strongDescr>normalization</strongDescr> methods to simplify the text, such as converting to <strongDescr></strongDescr>lowercase, <strongDescr>removing punctuation</strongDescr>, <strongDescr>stopwords</strongDescr>, and <strongDescr>lemmatization</strongDescr>.
                    </p>
                    <h3>III - Models</h3>
                    <p>
                        The project explores several models for the classification of music genres. <br>
                        <strongDescr>N-grams</strongDescr> use <strongDescr>trigrams</strongDescr> to generate new content, showing potential in capturing the lyrical styles of musical genres.<br> 
                        <strongDescr>Naive Bayes</strongDescr> and <strongDescr>Logistic Regression</strongDescr> are tested with different <strongDescr>Preprocessing</strongDescr> to examine their effectiveness in classification. 
                        Advanced approaches such as <strongDescr>TF-IDF</strongDescr> and <strongDescr>Word2Vec</strongDescr> are also implemented to enhance the capture of semantic relationships in the texts.<br>
                        <strongDescr>Neural Networks</strongDescr>, both <strongDescr>feedforward</strongDescr> and <strongDescr>recurrent</strongDescr>, are experimented with to assess their ability to handle the sequential data of lyrics. <br>
                        Each model is evaluated by its <strongDescr>Accuracy</strongDescr>, <strongDescr>Recall</strongDescr>, and <strongDescr>F1-score</strongDescr> to determine which method provides the best results for genre classification.

                    </p>
                </div>

            </div>
                <div class="project-item">
                    <h3>Microsoft Azure Project</h3>
                    <p>
                        This project leveraged Microsoft Azure's cloud solutions, including <strongDescr>Computer Vision</strongDescr> and <strongDescr>Machine Learning</strongDescr>, to predict outcomes on two distinct datasets selected from Kaggle.<br>
                        We utilized a <strongDescr>breast cancer</strongDescr> dataset, employing images for the computer vision component and tabular data for the machine learning aspect.<br>
                        Here are the links to the two <strongDescr>Datasets</strongDescr> we used:<br>
                        <a href="https://www.kaggle.com/datasets/truthisneverlinear/bach-breast-cancer-histology-images" target="_blank">Images dataset</a> and 
                        <a href="https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset" target="_blank">Table dataset</a>
                    </p>
                    <ul>
                        <li><img src="images/microsoftAzure/microsoftAzure_logo.png" alt="MicrosoftAzure Logo" class="logo-image"> Microsoft Azure</li>
                    </ul>
                    <button class="view-btn">See More</button>
                    <div class="project-description" style="display: none;">

                    <h3>I - Description</h3>
                    <p>
                        Utilize datasets of your choice to implement Computer Vision and Machine Learning using Microsoft Azure. <br>
                        To build a website for the cloud-based Machine Learning component, you must have access to an API provided by Microsoft Azure. <br>
                        For the Computer Vision component, you need to construct a Docker container to access its API.
                    </p>
                    <h3>II - Our solution</h3>
                    <p>
                        We used <strongDescr>Microsoft Azure</strongDescr> tools to train a <strongDescr>Computer Vision</strongDescr> model, which we then deployed locally using Docker <strongDescr>Docker</strongDescr>.<br>
                        Then, we employed <strongDescr>Machine Learning</strongDescr> capabilities to analyze tabular data.<br>
                        These combined technologies enabled us to identify various stages of cancer effectively with different data types.<br>
                        To integrate these components, we developed a streamlined <strongDescr>Flask</strongDescr> application.
                    </p>
                    <p>
                        <strong>Below is the architectural diagram that summarizes our setup:</strong>
                    </p>
                    <p>
                        <img src="images/microsoftAzure/architectureMicrosoftAzure.png" alt="Architecture MicrosoftAzure Diagram" class="full-width-image">
                    </p>
                </div>
            </div>

            <div class="project-item">
                <h3>Portfolio</h3>
                <p>
                    This <strongDescr>Website</strongDescr> was made to show the differents projects I made.<br>
                    It is hosted with <strongDescr>AWS</strongDescr>.<br>
                    This project is made completly in <strongDescr>HTML</strongDescr>, <strongDescr>CSS</strongDescr> and <strongDescr>JavaScript</strongDescr>.
                </p>
                <ul>
                    <li><img src="images/portfolio/html_logo.png" alt="HTML Logo" class="logo-image"> HTML</li>
                    <li><img src="images/portfolio/css_logo.svg" alt="CSS Logo" class="logo-image"> CSS</li>
                    <li><img src="images/portfolio/javascript_logo.png" alt="JavaScript Logo" class="logo-image"> JavaScript</li>
                </ul>
                <button class="view-btn">See More</button>
                <div class="project-description" style="display: none;">   
                   <p>
                        This <strongDescr>Website</strongDescr> is meticulously designed to showcase the complete <strongDescr>Portfolio</strongDescr> of projects I have created.<br>
                        I aimed to achieve a <strongDescr>Clean</strongDescr> and <strongDescr>Refined</strongDescr> aesthetic throughout the design, ensuring that each project is highlighted in a visually appealing and organized manner.
                    </p> 
                    <p>
                        There is also a small <strongDescr>GeoGuessr</strongDescr> like game hidden in the <strongDescr>Website</strongDescr>.<br>
                        I used the <strongDescr>Google API</strongDescr> and <strongDescr>JavaScript</strongDescr> to do it, but there are only two mounth of free API usage so it wont be able for a long time.
                    </p>
                </div>
            </div>

            <div class="project-item">
                <h3>Recommander System</h3>
                <p>
                    In this Project we had to do a <strongDescr>Recommander system</strongDescr> about movies. We used the dataset <strongDescr>ml-1m</strongDescr>.<br>
                    We needed to develop an algorithm to suggest one movie that might be liked by a couple of users.<br>
                    The project included cleaning datas with <strongDescr>Pandas</strongDescr>, dealing with the datas with <strongDescr>Numpy</strongDescr>. Testing some models with <strongDescr>Scipy</strongDescr> and <strongDescr>Scikit-Learn</strongDescr> to train models.
                </p>
                <ul>
                    <li><img src="images/recommanderSystem/numpy_logo.png" alt="Numpy Logo" class="logo-image"> Numpy</li>
                    <li><img src="images/recommanderSystem/pandas_logo.png" alt="Pandas Logo" class="logo-image"> Pandas</li>
                    <li><img src="images/recommanderSystem/scipy_logo.png" alt="Scipy Logo" class="logo-image"> Scipy</li>
                    <li><img src="images/recommanderSystem/sklearn_logo.svg" alt="Sklearn Logo" class="logo-image"> Scikit-Learn</li>
                </ul>
                <button class="view-btn">See More</button>
                <div class="project-description" style="display: none;">   
                   <p>
                        TO DO... 
                        <!-- But then did my own FunkySVD that... <strongDescr>#TODO</strongDescr> -->
                   
                    </p> 
                </div>
            </div>

            <div class="project-item">
                <h3>Tiger</h3>
                <p>
                    Tiger compilator from scratch in C++.
                </p>
                <ul>
                    <li><img src="images/tiger/c++_logo.png" alt="C++ Logo" class="logo-image"> C++</li>
                </ul>
            </div>

            <div class="project-item">
                <h3>42SH</h3>
                <p>
                    Reproduction of a shell from scratch in C / Lexing, Parsing, Executer.
                </p>
                <ul>
                    <li><img src="images/42sh/c_logo.png" alt="C Logo" class="logo-image"> C</li>
                </ul>
            </div>

            <!-- <div class="project-item">Project A - A brief description.</div>
            <div class="project-item">Project B - A brief description.</div>
            <div class="project-item">Project C - A brief description.</div>
            <div class="project-item">Project A - A brief description.</div>
            <div class="project-item">NLP Project - This project was a .</div>
            <div class="project-item">Sudoku CNN - Develop a CNN that is able to solve Sudoku.</div> -->
            <!-- More projects can be added here -->
                
        </div>
        <script>
            document.addEventListener("DOMContentLoaded", function() {
                const observer = new IntersectionObserver((entries) => {
                    entries.forEach(entry => {
                        if (entry.isIntersecting) {
                            entry.target.style.opacity = 1;
                            entry.target.style.transform = "translateY(0)"; // Ensure items transition to their final position smoothly
                        }
                    });
                }, {
                    rootMargin: '0px',
                    threshold: 0.1 // Adjust as needed
                });
            
                document.querySelectorAll('.project-item').forEach(item => {
                    observer.observe(item);
                });
            });
        </script>
    </section>
    <section id="about">
        <h2>About me</h2>
        <p>
            Hi there! I'm Florian, a student at <strongDescr>EPITA</strongDescr>, an esteemed <strongDescr>Informatics</strongDescr> and <strongDescr>Engineering</strongDescr> school where I specialize in programming, 
            <strongDescr>Artificial Intelligence</strongDescr> and <strongDescr>Datas</strongDescr>.<br>
            With a deep-rooted passion for technology, I have knowledge a variety of programming languages including <strongDescr>Python</strongDescr>, <strongDescr>Scala</strongDescr>, <strongDescr>C</strongDescr>, <strongDescr>C++</strongDescr>, <strongDescr>C#</strongDescr> and more.
        </p>    
        <p>
            Currently, I am immersed in AI studies, adept at utilizing tools such as <strongDescr>Scikit-learn</strongDescr>, <strongDescr>PyTorch</strongDescr>, <strongDescr>TensorFlow</strongDescr>, <strongDescr>NumPy</strongDescr>, 
            <strongDescr>Pandas</strongDescr>, and more to solve complex problems and innovate solutions.<br>
            My academic journey also includes a <strongDescr>Bachelor's degree</strongDescr> in <strongDescr>Mathematics</strongDescr>, a field I thoroughly enjoy and excel in.
        </p>
        <p>
            My professional experience includes serving as a <strongDescr>Mathematics Tutor</strongDescr> at <strongDescr>La Sorbonne (UPMC)</strongDescr> and working as a <strongDescr>Software Developer</strongDescr> at <strongDescr>A26 BLM</strongDescr>, an architecture company.<br>
            These roles have not only honed my technical skills but also enriched my ability to teach and collaborate effectively.
        </p>
        <p>
            I am always on the lookout for intriguing job opportunities where I can continue to learn and grow. I believe that the ever-evolving field of technology offers endless possibilities for innovation and discovery.
        </p>
        <p>
            Outside of my professional interests, I am an avid sports enthusiast. I enjoy <strongDescr>Climbing</strongDescr>, dedicating 2 to 3 sessions a week to it, and playing <strongDescr>Basketball</strongDescr>. <br>
            These activities help me stay active and balanced, providing a perfect counterpoint to my academic and professional pursuits.
        </p>
        <p>
            Thank you for visiting my website. I look forward to connecting with you! So do not hesitate to contact me with the links in the contact section.
        </p>

        <h2>You can also check out my Resume here:</h2>
        <a href="Florian_RES_2024.pdf" target="_blank">
            <button>View Resume</button>
        </a>

        <h2>Check out my GitHub here:</h2>
        <a href="https://github.com/FlorianSegard" target="_blank">
            <img src="images/github_logo.png" alt="GitHub" style="width:50px; height:50px; border:none;">
        </a>
    
    </section>


    <section id="contact">
        <h2>Contact</h2>
        <p>Have questions? Want to get in touch? Here's how you can reach me:</p>
        <address>
            <strong>Email:</strong> <a href="mailto:florian.segard-gahery@epita.fr">florian.segard-gahery@epita.fr</a><br>
            <strong>LinkedIn:</strong> <a href="https://www.linkedin.com/in/florian-segard-gahery-0999221a8/" target="_blank">LinkedIn Profile</a><br>
        </address>
        <p></p>

        <!-- Calendly badge widget begin -->
        <link href="https://assets.calendly.com/assets/external/widget.css" rel="stylesheet">
        <script src="https://assets.calendly.com/assets/external/widget.js" type="text/javascript" async></script>
        <script type="text/javascript">window.onload = function() { Calendly.initBadgeWidget({ url: 'https://calendly.com/floriansegard', text: 'Schedule a meeting with me', color: '#a61818', textColor: '#ffffff', branding: true }); }</script>
        <!-- Calendly badge widget end -->

    </section>


    <footer>
        <p onclick="startGame()">Copyright © 2024 Florian Segard-Gahery</p>
    </footer>
    <div id="gameContainer" style="display:none;">
        <button id="closeButton" onclick="closeGame()">&times;</button>
        <div id="map-container" class="view-container">
            <div id="street-view" class="half-view"></div>
            <div id="map" class="half-view"></div>
        </div>
        <div id="resultModal" style="display:none;">
            <div id="resultModalContent">
                <span onclick="closeModal()">&times;</span>
                <p id="distanceResult">Distance from original location: 0 km</p>
                <div class="progress-bar-wrapper">
                    <div id="scoreBar" class="progress-bar"></div>
                </div>
                <p id="scoreResult">Score: 0</p>

            </div>
            <button class="game-button_next" onclick="nextMap()">Next Map</button>

        </div>
        
        <div id="buttonContainer">
            <button id="validateGuess" class="game-button" onclick="validateGuess()">Validate Guess</button>
            <button class="game-button" onclick="resetView()">Reset View</button>
        </div>
        <div class="score-counter">
            <span id="gameCount">Game: 1/5</span> | <span id="totalScore">Total Score: 0</span>
        </div>
    
    </div>
    <div id="finalScoreModal">
        <div id="finalScoreModalContent">
            <span onclick="closeFinalScoreModal()">&times;</span>
            <h2>Final Score</h2>
            <div class="progress-bar-wrapper">
                <div id="finalScoreBar" class="progress-bar"></div>
            </div>
            <p id="finalScoreResult">Score: 0</p>
        </div>
    </div>

    
    <script src="https://maps.googleapis.com/maps/api/js?key=AIzaSyBCMm6CS82t6Hv_ymU2Es6uo63HlJ6J0qg&v=weekly" async defer></script>
    <script src="app.js"></script>
    <script src="viewmore.js"></script>
    <script src="headersmaller.js"></script>
</body>
</html>
